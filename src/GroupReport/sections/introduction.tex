\section{Introduction}

As the era of artificial intelligence and big data, a program that runs on single core machine has fundamental limitation in terms of computation power. In hardware manufacturing industry, developing SoC optimized to such computations is already on-going process. Still, thanks to the end of Moore's law and Dennard's scaling, software implementation that synchronizes multiple threads is unavoidable in order to achieve reasonably scalable computing.

There has been an aggressive development of languages and libraries that exploits concurrency such as CUDA, OpenCL, TensorFLow, PyTorch, and etc. Inside each implementation, concurrent programming is what really drives the program to be correct and efficient. Some libraries hide the complex logic for concurrency underneath, and some provides let the programmers fill in the gaps for their desired logic.

Multi-threaded codes often come up with the problem called data race. It means multiple threads access the same memory location concurrently and at least one of them is writing. It may cause computation give wrong output depending on their execution order. It can be resolved by using exclusive locks to control accesses to that memory. But abusing lock will interrupt other threads' execution and it will lead to longer execution time.
So it's important to protect shared memory location by using locks and also minimizing the interval(execution time) between lock and unlock. But it's hard to be achieved by hand, and some of races can be only detected on runtime.
Our project MiniCS is solution for this problem. It produces population of candidate codes with locks and perform GA to get best code that's without data race and has minimum "lock interval" (Lock interval means "execution time between lock including lock and unlock themselves" on this paper).